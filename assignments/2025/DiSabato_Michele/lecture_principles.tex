\textbf{1.} \underline{Methods for verification:} While verification consists in checking if the software/product works correctly and meets its technical specifications, the goal of validation is making sure that the product meets the customer’s/user’s needs. As said in the introduction, in the context of my research, the “product” usually consists in the output of simulations aimed at showcasing the practical aspects of a proposed methodology. These simulations are computationally intensive. Re-running them because of slight mistakes in the code, such as mishandling in the fault-detection and fault-tolerance of one or more jobs in the distributed system used to run the code, leads to significant delays. To avoid these, it could be useful to implement a more systematic control of “whether we are building the product right”, as stated in the lecture. This not only consists in the use of static techniques (such as code walkthroughs), but also dynamic techniques. For example, if part of a simulation is written in R but requires a function that exists only in Python, one needs to re-implement that function in R. In such cases, it is useful to verify that the R version produces the same output as the original Python implementation. Alternatively, when multiple parallelization schemes are possible, it's useful to verify on smaller-scale simulations that all schemes produce identical results before selecting the fastest implementation. What I gained from the lectures is firstly an understanding of the research field of software testing and secondly the importance of performing code checks and tests systematically, methodically, and with a user-oriented mindset.\par\vspace{0.7em}
\noindent
\textbf{2.} \underline{Version control and pragmatic software engineering “rules”:} In my research, version control is essential because simulations are often run under different settings, for example by varying how synthetic data are generated or how the null and alternative hypotheses are formulated ($H_0$). Since research is not a linear process, it is common to explore one path, realize later that another design choice was better, and then need to revert to an earlier setup. With version control, I can always revert back to a previous version of the code and simulation parameters. This avoids repeating costly runs from scratch and keeps a clear history of how the project evolved. GitHub is particularly useful in ensuring this: even if the project does not involve a big research group, keeping a GitHub repository is useful to track code changes.
Coding standards are equally important in this context. For example, when submitting newly developed R packages to CRAN\footnote{the official online repository where R packages are published and shared, see \cite{cran}}, one should avoid duplicating the same functionality in multiple places. In my simulations, several simulation settings rely on very similar dataset creation steps. Instead of writing slightly different functions that all do almost the same thing, I restructure the code so that one well-written, standardized function handles this step for every setting. This reduces redundancy, makes the code easier to maintain, and ensures that if I need to update or fix something, I only need to do it in one place.
