My research area pertains to mathematical methods for clustering and statistical hypothesis testing in functional data analysis. In ordinary multivariate statistics and data analysis, each datum is a vector of features and datasets are tabular datasets. On the other hand, in functional data analysis each datum is a map from one space to another. For example, time series can be modeled as functions of time and images can be viewed as function of the pixel's locations/indices. The central task of hypothesis testing in this field is to assess whether evidence in the data (e.g. time series or images) contradicts a null hypothesis $H_0$ in favor of an alternative $H_1$. Practically, we quantify how inconsistent the observed data are with $H_0$. If strong inconsistencies are detected, then this is counted as evidence in favor of the alternative hypothesis $H_1$. The goal is not to prove that a statement is true, but to supply reliable procedures that let scientists (domain experts) draw such conclusions from arbitrary datasets. The methodologies developed in this field of statistics are designed to fulfill certain theoretical guarantees, such as a desired control over false discoveries. These occur if the null hypothesis is wrongly rejected. 
Papers in this field often pair theoretical proofs with simulations based on synthetic datasets, that illustrate the proposed testing method, highlight its performance, and expose computational bottlenecks. Using SE terminology, these simulations are the software “product” and the “users” coincide with the members of the research group, who would like to draw conclusions based on the output of the simulations. Working with time series poses significant computational challenges, as testing methodologies often require high-resolution data. The theoretical proofs need to come to terms with the actual practical implementation of these methodologies which introduces numerical errors and sometimes compromises with theoretical assumptions. Moreover, it may sometimes be necessary to use packages written in a different programming language than the one used for the simulations (usually R). In such cases, workarounds are often required to ensure compatibility.

A concrete illustration comes from gait analysis: comparing knee-flexion curves during a one-leg hop for distance between previously injured patients and healthy controls. Here one would test \(H_0: \mu_{\text{injured}}(t) = \mu_{\text{healthy}}(t)\ \text{ for all times } t\) (the knee flexion dynamics of injured and healthy patients are the same) against the opposite \(H_1: \mu_{\text{injured}}(t) \neq \mu_{\text{healthy}}(t)\) for some time \(t\). Multiple methods rooted in functional data analysis might, for example, highlight differences at the take-off and landing phases of the jump. This example shows that the output of this field often benefits from the opinion of domain experts who aren’t familiar with mathematics or machine learning.

%The p-value measures how likely the observed discrepancy is under $H_0$. A small p-value does not prove $H_0$ false but suggests the data are unlikely if $H_0$ holds, thus supporting $H_1$.

%My research also extends into the field of time series clustering, which is often computationally challenging. This is primarily because time series are recorded at many time steps, leading to vectors of considerable length.
